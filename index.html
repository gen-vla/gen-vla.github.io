<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A framework that enhances the generalization of Vision-Language-Action models by preserving pretrained representations.">
  <meta name="keywords" content="VLA, Vision-Language-Action, Robotics, Generalization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Enhancing Generalization in Vision-Language-Action Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Enhanced carousel styles */
    .demo-carousel {
      position: relative;
      overflow: hidden;
      margin: 2rem 0;
    }

    .carousel-container {
      display: flex;
      transition: transform 0.5s ease;
      gap: 1rem;
    }

    .carousel-item {
      flex: 0 0 48%;
      padding: 1rem;
      background: #f8f9fa;
      border-radius: 12px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
    }

    .carousel-item:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 15px rgba(0, 0, 0, 0.15);
    }

    .carousel-item img {
      width: 100%;
      height: 200px;
      object-fit: cover;
      border-radius: 8px;
      margin-bottom: 1rem;
    }

    .carousel-item p {
      font-weight: 600;
      color: #363636;
      margin: 0;
      text-align: center;
    }

    .carousel-nav {
      display: flex;
      justify-content: center;
      align-items: center;
      margin-top: 1.5rem;
      gap: 1rem;
    }

    .carousel-btn {
      background: #3273dc;
      color: white;
      border: none;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      cursor: pointer;
      font-size: 1.2rem;
      transition: background-color 0.3s ease, transform 0.2s ease;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .carousel-btn:hover {
      background: #2366d1;
      transform: scale(1.1);
    }

    .carousel-btn:disabled {
      background: #dbdbdb;
      cursor: not-allowed;
      transform: none;
    }

    .carousel-indicators {
      display: flex;
      gap: 0.5rem;
    }

    .carousel-dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #dbdbdb;
      cursor: pointer;
      transition: background-color 0.3s ease, transform 0.2s ease;
    }

    .carousel-dot.active {
      background: #3273dc;
      transform: scale(1.2);
    }

    .carousel-dot:hover {
      background: #2366d1;
    }

    @media (max-width: 768px) {
      .carousel-item {
        flex: 0 0 100%;
      }

      .carousel-item img {
        height: 150px;
      }
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://gen-vla.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                    <a href="https://shroglck.github.io/" class="author-link">Shresth Grover</a>¹*,
            </span>
            <span class="author-block">
                    <a href="https://akshaygopalkr.github.io/" class="author-link">Akshay Gopalkrishnan</a>¹*,</span>
            <span class="author-block">
              <a href="https://albertboai.com" class="author-link">Bo Ai</a>¹,
            </span>
            <span class="author-block">
              <a href="http://hichristensen.net/" class="author-link">Henrik I. Christensen</a>¹,
            </span>
            <span class="author-block">
                        <a href="https://cseweb.ucsd.edu/~haosu/index.html" class="author-link">Hao Su</a>¹²,
            </span>
            <span class="author-block">
                     <a href="https://xuanlinli17.github.io/" class="author-link">Xuanlin Li</a>²
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">¹UC San Diego,</span>
            <span class="author-block">²Hillbot</span>
            <span class="author-block">*Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2509.11417"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://gen-vla.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-video"></i>
                  </span>
                  <span>Project Page</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://gen-vla.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        Our framework improves the robustness and generalization of robot manipulation policies by preserving the rich features of pretrained vision-language models.
      </h2>
    </div>
  </div>
</section>

<section class="section">                                                          <div class="container is-max-desktop">                                             <div class="columns is-centered">                                                  <div class="column has-text-centered">                                             <img src="./videos/promo_.gif" alt="Demonstration of the VLA model">           </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-language-action (VLA) models, finetuned from powerful pretrained vision-language models (VLMs), promise to create generalist robots. However, this finetuning process often degrades the very representations that make them powerful, limiting generalization. We propose a framework that preserves these pretrained features while adapting them for robot manipulation. Our method introduces a dual-encoder design to retain features, a string-based action tokenizer to align actions with language, and a co-training strategy to balance robot and vision-language data. Our evaluations show significant improvements in robustness, generalization, and overall task success.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
         <img src="./images/figure2-method.png" alt="Method Overview Diagram">
      </div>
    </div>
      <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our framework is built on three key ideas to prevent representation degradation. <strong>(1) Partially-Frozen Visual Encoders:</strong> We use two encoders—one frozen to preserve robust, pretrained VLM features and one trainable to adapt to the specific robot task. <strong>(2) String-Based Action Tokenizer:</strong> We represent continuous robot actions as strings, unifying them with the text-based pretraining of the language model. <strong>(3) Co-Training Strategy:</strong> We mix robot demonstration data with vision-language datasets that emphasize spatial reasoning, preventing the model from overfitting to robot-specific data and enhancing its generalization capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Key Findings & Results</h2>


    <!-- Reasoning Capabilities -->
     <div class="columns is-centered">
        <div class="column is-half has-text-centered">
            <img src="./images/vlm_benchmark_reults.png" alt="Radar chart of VQA benchmark performance">
            <p class="is-size-7"><em>Our models (solid lines) significantly outperform baselines (dashed lines) on five VQA benchmarks.</em></p>
        </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4 has-text-centered">Retaining Reasoning Capabilities</h3>
        <p class="has-text-justified">
          Standard VLA finetuning harms the model's ability to perform general visual reasoning. Our training recipe allows the model to retain significantly higher performance on standard VQA benchmarks, demonstrating that it doesn't just learn robotic actions but also preserves its core reasoning abilities.
        </p>
      </div>
    </div>
    
    <!-- Generalization Three Plots -->
    <div class="columns is-centered is-vcentered">
        <div class="column is-one-third has-text-centered">
            <img src="./images/vis_matching.png" alt="Bar chart for Visual Matching">
            <p class="is-size-7"><em>SimplerEnv Visual Matching</em></p>
        </div>
        <div class="column is-one-third has-text-centered">
            <img src="./images/var_agg.png" alt="Bar chart for Visual Variant Aggregation">
            <p class="is-size-7"><em>SimplerEnv Variant Aggregation (OOD)</em></p>
        </div>
        <div class="column is-one-third has-text-centered">
            <img src="./images/text_ag.png" alt="Bar chart for Language Robustness">
            <p class="is-size-7"><em>Language Robustness</em></p>
        </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4 has-text-centered">Improving Generalization and Robustness</h3>
        <p class="has-text-justified">
          A key challenge for robots is generalizing to novel scenes and instructions. Baseline models show a significant drop in performance when backgrounds change or instructions are paraphrased. Our approach demonstrates substantially stronger generalization, maintaining high success rates even with out-of-distribution (OOD) visual and language inputs.
        </p>
      </div>
    </div>


    <!-- Real World -->
    <div class="columns is-centered">
        <div class="column is-full-width has-text-centered">
            <img src="./images/real_perf.png" alt="Qualitative results of robot picking knife and carrot">
            <p class="is-size-7"><em>Real World Performance.</em></p>
        </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4 has-text-centered">Robust Performance in the Real World</h3>
        <p class="has-text-justified">
          In real-world tests, our models consistently outperform baselines, especially in the presence of distracting objects. While baseline models often get confused by distractors (e.g., picking a carrot instead of a knife), our model demonstrates a more robust understanding of the task, successfully completing the instructed action.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Enhanced Demonstration Carousel -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Demonstrations</h2>
        <div class="content has-text-centered">
          <p>
            Here we showcase sample demonstrations of our model's performance in various scenarios, highlighting its generalization capabilities.
          </p>
        </div>

        <div class="demo-carousel">
          <div class="carousel-container" id="carousel-container">
            <div class="carousel-item">
              <img src="./videos/video_1.gif" alt="Demonstration for picking up a carrot and placing it on plate">
              <p>Task 1: Put carrot on plate.</p>
            </div>
            <div class="carousel-item">
              <img src="./videos/video_2.gif" alt="Demonstration for putting knife on cloth">
              <p>Task 2: Put knife on cloth.</p>
            </div>
            <div class="carousel-item">
              <img src="./videos/video_3.gif" alt="Demonstration for placing carrot on a plate">
              <p>Task 3: Place the carrot on the plate.</p>
            </div>
            <div class="carousel-item">
              <img src="./videos/video_6.gif" alt="Demonstration for placing object on target">
              <p>Task 4: Place carrot on plate.</p>
            </div>
            <div class="carousel-item">
              <img src="./videos/video_7.gif" alt="Additional demonstration">
              <p>Task 5: Put carrot on plate.</p>
            </div>
            <div class="carousel-item">
              <img src="./videos/video_5.gif" alt="Additional demonstration">
              <p>Task 6: Put carrot on yellow plate.</p>
            </div>
          </div>

          <div class="carousel-nav">
            <button class="carousel-btn" id="prev-btn">‹</button>
            <div class="carousel-indicators" id="carousel-indicators"></div>
            <button class="carousel-btn" id="next-btn">›</button>
          </div>
        </div>
      </div>
    </div>
    <!--/ Enhanced Demonstration Carousel -->

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{grover2025enhancing,
  title={Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations},
  author={Grover, Shresth and Gopalkrishnan, Akshay and Ai, Bo and Christensen, Henrik I. and Su, Hao and Li, Xuanlin},
  journal={arXiv preprint arXiv:2509.11417},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
class DemoCarousel {
  constructor() {
    this.container = document.getElementById('carousel-container');
    if (!this.container) return; // Exit if carousel doesn't exist
    this.prevBtn = document.getElementById('prev-btn');
    this.nextBtn = document.getElementById('next-btn');
    this.indicators = document.getElementById('carousel-indicators');
    this.items = this.container.querySelectorAll('.carousel-item');
    this.currentIndex = 0;
    
    this.init();
  }

  init() {
    this.updateItemsPerPage();
    this.createIndicators();
    this.bindEvents();
    this.updateCarousel();
    this.updateButtons();
  }

  updateItemsPerPage() {
      this.itemsPerPage = window.innerWidth <= 768 ? 1 : 2;
      this.totalPages = Math.ceil(this.items.length / this.itemsPerPage);
  }

  createIndicators() {
    if (!this.indicators) return;
    this.indicators.innerHTML = '';
    for (let i = 0; i < this.totalPages; i++) {
      const dot = document.createElement('div');
      dot.className = 'carousel-dot';
      dot.addEventListener('click', () => this.goToPage(i));
      this.indicators.appendChild(dot);
    }
  }

  bindEvents() {
    if (!this.prevBtn || !this.nextBtn) return;
    this.prevBtn.addEventListener('click', () => this.prevPage());
    this.nextBtn.addEventListener('click', () => this.nextPage());

    // Handle window resize
    window.addEventListener('resize', () => {
      this.updateItemsPerPage();
      this.currentIndex = Math.min(this.currentIndex, this.totalPages - 1);
      this.createIndicators();
      this.updateCarousel();
      this.updateButtons();
    });

    // Touch/swipe support
    let startX = 0;
    let startY = 0;
    let currentX = 0;
    let currentY = 0;

    this.container.addEventListener('touchstart', (e) => {
      startX = e.touches[0].clientX;
      startY = e.touches[0].clientY;
    }, { passive: true });

    this.container.addEventListener('touchmove', (e) => {
      currentX = e.touches[0].clientX;
      currentY = e.touches[0].clientY;
    }, { passive: true });

    this.container.addEventListener('touchend', () => {
      const diffX = startX - currentX;
      const diffY = startY - currentY;

      // Only register horizontal swipes
      if (Math.abs(diffX) > Math.abs(diffY) && Math.abs(diffX) > 50) {
        if (diffX > 0) {
          this.nextPage();
        } else {
          this.prevPage();
        }
      }
    }, { passive: true });
  }

  updateCarousel() {
    const itemWidthPercentage = 100 / this.items.length;
    const containerWidthPercentage = itemWidthPercentage * this.itemsPerPage;
    const offset = this.currentIndex * (100 / this.totalPages);
    
    this.container.style.transform = `translateX(-${offset}%)`;
    
    const dots = this.indicators.querySelectorAll('.carousel-dot');
    dots.forEach((dot, index) => {
      dot.classList.toggle('active', index === this.currentIndex);
    });
  }

  updateButtons() {
    if (!this.prevBtn || !this.nextBtn) return;
    this.prevBtn.disabled = this.currentIndex === 0;
    this.nextBtn.disabled = this.currentIndex === this.totalPages - 1;
  }

  prevPage() {
    if (this.currentIndex > 0) {
      this.currentIndex--;
      this.updateCarousel();
      this.updateButtons();
    }
  }

  nextPage() {
    if (this.currentIndex < this.totalPages - 1) {
      this.currentIndex++;
      this.updateCarousel();
      this.updateButtons();
    }
  }

  goToPage(index) {
    if (index >= 0 && index < this.totalPages) {
      this.currentIndex = index;
      this.updateCarousel();
      this.updateButtons();
    }
  }
}

// Initialize carousel when DOM is loaded
document.addEventListener('DOMContentLoaded', () => {
  new DemoCarousel();
});
</script>
</body>
</html>
